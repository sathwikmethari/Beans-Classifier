{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score,roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('Dry_Bean_Dataset.xlsx')\n",
    "from Data_Cleaning import outlier_replacer\n",
    "from Data_Cleaning2 import Data_Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,x_cols=outlier_replacer(data)\n",
    "x_train,x_test,y_train,y_test,scaler,Encoder,pca=Data_Cleaner(x,y,x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict={\n",
    "    \"LogisticRegression\":LogisticRegression(),\n",
    "    \"SupportVector\":SVC(),\n",
    "    \"NaiveBayes\":GaussianNB(),\n",
    "    \"KnnClassifier\":KNeighborsClassifier(),\n",
    "    \"DecisionTree\":DecisionTreeClassifier(),\n",
    "    \"RandomForest\":RandomForestClassifier(),\n",
    "    \"AdaBoost\":AdaBoostClassifier(),\n",
    "    \"GradientBoost\":GradientBoostingClassifier(),\n",
    "    \"XgbClassifier\":XGBClassifier()    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Training AccuracyScore:0.9335\n",
      "Training F1Score:0.9335\n",
      "Training PrecisionScore:0.9337\n",
      "Training RecallScore:0.9335\n",
      "Test AccuracyScore:0.9289\n",
      "Test F1Score:0.9290\n",
      "Test PrecisionScore:0.9294\n",
      "Test RecallScore:0.9289\n",
      "\n",
      "\n",
      "SupportVector\n",
      "Training AccuracyScore:0.9417\n",
      "Training F1Score:0.9418\n",
      "Training PrecisionScore:0.9421\n",
      "Training RecallScore:0.9417\n",
      "Test AccuracyScore:0.9347\n",
      "Test F1Score:0.9350\n",
      "Test PrecisionScore:0.9356\n",
      "Test RecallScore:0.9347\n",
      "\n",
      "\n",
      "NaiveBayes\n",
      "Training AccuracyScore:0.9067\n",
      "Training F1Score:0.9065\n",
      "Training PrecisionScore:0.9071\n",
      "Training RecallScore:0.9067\n",
      "Test AccuracyScore:0.9029\n",
      "Test F1Score:0.9029\n",
      "Test PrecisionScore:0.9034\n",
      "Test RecallScore:0.9029\n",
      "\n",
      "\n",
      "KnnClassifier\n",
      "Training AccuracyScore:0.9569\n",
      "Training F1Score:0.9569\n",
      "Training PrecisionScore:0.9570\n",
      "Training RecallScore:0.9569\n",
      "Test AccuracyScore:0.9301\n",
      "Test F1Score:0.9303\n",
      "Test PrecisionScore:0.9306\n",
      "Test RecallScore:0.9301\n",
      "\n",
      "\n",
      "DecisionTree\n",
      "Training AccuracyScore:1.0000\n",
      "Training F1Score:1.0000\n",
      "Training PrecisionScore:1.0000\n",
      "Training RecallScore:1.0000\n",
      "Test AccuracyScore:0.9120\n",
      "Test F1Score:0.9124\n",
      "Test PrecisionScore:0.9132\n",
      "Test RecallScore:0.9120\n",
      "\n",
      "\n",
      "RandomForest\n",
      "Training AccuracyScore:1.0000\n",
      "Training F1Score:1.0000\n",
      "Training PrecisionScore:1.0000\n",
      "Training RecallScore:1.0000\n",
      "Test AccuracyScore:0.9444\n",
      "Test F1Score:0.9445\n",
      "Test PrecisionScore:0.9448\n",
      "Test RecallScore:0.9444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Training AccuracyScore:0.7359\n",
      "Training F1Score:0.7027\n",
      "Training PrecisionScore:0.7608\n",
      "Training RecallScore:0.7359\n",
      "Test AccuracyScore:0.7265\n",
      "Test F1Score:0.6921\n",
      "Test PrecisionScore:0.7371\n",
      "Test RecallScore:0.7265\n",
      "\n",
      "\n",
      "GradientBoost\n",
      "Training AccuracyScore:0.9572\n",
      "Training F1Score:0.9572\n",
      "Training PrecisionScore:0.9573\n",
      "Training RecallScore:0.9572\n",
      "Test AccuracyScore:0.9325\n",
      "Test F1Score:0.9327\n",
      "Test PrecisionScore:0.9330\n",
      "Test RecallScore:0.9325\n",
      "\n",
      "\n",
      "XgbClassifier\n",
      "Training AccuracyScore:0.9998\n",
      "Training F1Score:0.9998\n",
      "Training PrecisionScore:0.9998\n",
      "Training RecallScore:0.9998\n",
      "Test AccuracyScore:0.9384\n",
      "Test F1Score:0.9386\n",
      "Test PrecisionScore:0.9391\n",
      "Test RecallScore:0.9384\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models_dict))):\n",
    "    model=list(models_dict.values())[i]\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    y_train_pred=model.predict(x_train)\n",
    "    y_test_pred=model.predict(x_test)\n",
    "\n",
    "    train_acc=accuracy_score(y_train,y_train_pred)\n",
    "    train_f1=f1_score(y_train,y_train_pred,average='weighted')\n",
    "    train_prec=precision_score(y_train,y_train_pred,average='weighted')\n",
    "    train_recall=recall_score(y_train,y_train_pred,average='weighted')\n",
    "    #train_roc=roc_auc_score(y_train,y_train_pred,average='weighted',multi_class=\"ovo\")\n",
    "\n",
    "    test_acc=accuracy_score(y_test,y_test_pred)\n",
    "    test_f1=f1_score(y_test,y_test_pred,average='weighted')\n",
    "    test_prec=precision_score(y_test,y_test_pred,average='weighted')\n",
    "    test_recall=recall_score(y_test,y_test_pred,average='weighted')\n",
    "    #test_roc=roc_auc_score(y_test,y_test_pred,average='weighted',multi_class='ovo')\n",
    "\n",
    "    print(list(models_dict.keys())[i])\n",
    "    print(\"Training AccuracyScore:{:.4f}\".format(train_acc))\n",
    "    print(\"Training F1Score:{:.4f}\".format(train_f1))\n",
    "    print(\"Training PrecisionScore:{:.4f}\".format(train_prec))\n",
    "    print(\"Training RecallScore:{:.4f}\".format(train_recall))\n",
    "    #print(\"RocAocScore:{:.4f}\".format(train_roc))\n",
    "    print(\"Test AccuracyScore:{:.4f}\".format(test_acc))\n",
    "    print(\"Test F1Score:{:.4f}\".format(test_f1))\n",
    "    print(\"Test PrecisionScore:{:.4f}\".format(test_prec))\n",
    "    print(\"Test RecallScore:{:.4f}\".format(test_recall))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'colsample_bytree': np.float64(0.8738286191519333), 'gamma': np.float64(0.043934055621328405), 'learning_rate': np.float64(0.05164743203260611), 'max_depth': 11, 'min_child_weight': 1, 'n_estimators': 314, 'reg_alpha': np.float64(0.5956387406078443), 'reg_lambda': np.float64(0.5715761885501583), 'subsample': np.float64(0.7647363656589075)}\n",
      "Best accuracy:  0.9470215203224385\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 400),\n",
    "    'max_depth': randint(3, 25),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0.1, 1)\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=100,\n",
    "                                   scoring='accuracy', n_jobs=-1, cv=5, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best accuracy: \", random_search.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
