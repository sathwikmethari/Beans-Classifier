{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score,roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('Dry_Bean_Dataset.xlsx')\n",
    "from Data_Cleaning import outlier_replacer\n",
    "from Data_Cleaning2 import Data_Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,x_cols=outlier_replacer(data)\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test,scaler,Encoder,pc=Data_Cleaner(x,y,x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict={\n",
    "    \"LogisticRegression\":LogisticRegression(),\n",
    "    \"SupportVector\":SVC(),\n",
    "    \"NaiveBayes\":GaussianNB(),\n",
    "    \"KnnClassifier\":KNeighborsClassifier(),\n",
    "    \"DecisionTree\":DecisionTreeClassifier(),\n",
    "    \"RandomForest\":RandomForestClassifier(),\n",
    "    \"AdaBoost\":AdaBoostClassifier(),\n",
    "    \"GradientBoost\":GradientBoostingClassifier(),\n",
    "    \"XgbClassifier\":XGBClassifier()    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Training AccuracyScore:0.9320\n",
      "Training F1Score:0.9320\n",
      "Training PrecisionScore:0.9322\n",
      "Training RecallScore:0.9320\n",
      "Test AccuracyScore:0.9283\n",
      "Test F1Score:0.9283\n",
      "Test PrecisionScore:0.9288\n",
      "Test RecallScore:0.9283\n",
      "\n",
      "\n",
      "SupportVector\n",
      "Training AccuracyScore:0.9429\n",
      "Training F1Score:0.9430\n",
      "Training PrecisionScore:0.9433\n",
      "Training RecallScore:0.9429\n",
      "Test AccuracyScore:0.9370\n",
      "Test F1Score:0.9371\n",
      "Test PrecisionScore:0.9376\n",
      "Test RecallScore:0.9370\n",
      "\n",
      "\n",
      "NaiveBayes\n",
      "Training AccuracyScore:0.9050\n",
      "Training F1Score:0.9048\n",
      "Training PrecisionScore:0.9053\n",
      "Training RecallScore:0.9050\n",
      "Test AccuracyScore:0.9029\n",
      "Test F1Score:0.9027\n",
      "Test PrecisionScore:0.9037\n",
      "Test RecallScore:0.9029\n",
      "\n",
      "\n",
      "KnnClassifier\n",
      "Training AccuracyScore:0.9564\n",
      "Training F1Score:0.9565\n",
      "Training PrecisionScore:0.9566\n",
      "Training RecallScore:0.9564\n",
      "Test AccuracyScore:0.9368\n",
      "Test F1Score:0.9368\n",
      "Test PrecisionScore:0.9373\n",
      "Test RecallScore:0.9368\n",
      "\n",
      "\n",
      "DecisionTree\n",
      "Training AccuracyScore:1.0000\n",
      "Training F1Score:1.0000\n",
      "Training PrecisionScore:1.0000\n",
      "Training RecallScore:1.0000\n",
      "Test AccuracyScore:0.9168\n",
      "Test F1Score:0.9167\n",
      "Test PrecisionScore:0.9167\n",
      "Test RecallScore:0.9168\n",
      "\n",
      "\n",
      "RandomForest\n",
      "Training AccuracyScore:1.0000\n",
      "Training F1Score:1.0000\n",
      "Training PrecisionScore:1.0000\n",
      "Training RecallScore:1.0000\n",
      "Test AccuracyScore:0.9448\n",
      "Test F1Score:0.9448\n",
      "Test PrecisionScore:0.9449\n",
      "Test RecallScore:0.9448\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Training AccuracyScore:0.6840\n",
      "Training F1Score:0.6626\n",
      "Training PrecisionScore:0.7363\n",
      "Training RecallScore:0.6840\n",
      "Test AccuracyScore:0.6844\n",
      "Test F1Score:0.6590\n",
      "Test PrecisionScore:0.7386\n",
      "Test RecallScore:0.6844\n",
      "\n",
      "\n",
      "GradientBoost\n",
      "Training AccuracyScore:0.9566\n",
      "Training F1Score:0.9566\n",
      "Training PrecisionScore:0.9567\n",
      "Training RecallScore:0.9566\n",
      "Test AccuracyScore:0.9343\n",
      "Test F1Score:0.9344\n",
      "Test PrecisionScore:0.9348\n",
      "Test RecallScore:0.9343\n",
      "\n",
      "\n",
      "XgbClassifier\n",
      "Training AccuracyScore:0.9990\n",
      "Training F1Score:0.9990\n",
      "Training PrecisionScore:0.9990\n",
      "Training RecallScore:0.9990\n",
      "Test AccuracyScore:0.9458\n",
      "Test F1Score:0.9459\n",
      "Test PrecisionScore:0.9463\n",
      "Test RecallScore:0.9458\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models_dict))):\n",
    "    model=list(models_dict.values())[i]\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    y_train_pred=model.predict(x_train)\n",
    "    y_test_pred=model.predict(x_test)\n",
    "\n",
    "    train_acc=accuracy_score(y_train,y_train_pred)\n",
    "    train_f1=f1_score(y_train,y_train_pred,average='weighted')\n",
    "    train_prec=precision_score(y_train,y_train_pred,average='weighted')\n",
    "    train_recall=recall_score(y_train,y_train_pred,average='weighted')\n",
    "    #train_roc=roc_auc_score(y_train,y_train_pred,average='weighted',multi_class=\"ovo\")\n",
    "\n",
    "    test_acc=accuracy_score(y_test,y_test_pred)\n",
    "    test_f1=f1_score(y_test,y_test_pred,average='weighted')\n",
    "    test_prec=precision_score(y_test,y_test_pred,average='weighted')\n",
    "    test_recall=recall_score(y_test,y_test_pred,average='weighted')\n",
    "    #test_roc=roc_auc_score(y_test,y_test_pred,average='weighted',multi_class='ovo')\n",
    "\n",
    "    print(list(models_dict.keys())[i])\n",
    "    print(\"Training AccuracyScore:{:.4f}\".format(train_acc))\n",
    "    print(\"Training F1Score:{:.4f}\".format(train_f1))\n",
    "    print(\"Training PrecisionScore:{:.4f}\".format(train_prec))\n",
    "    print(\"Training RecallScore:{:.4f}\".format(train_recall))\n",
    "    #print(\"RocAocScore:{:.4f}\".format(train_roc))\n",
    "    print(\"Test AccuracyScore:{:.4f}\".format(test_acc))\n",
    "    print(\"Test F1Score:{:.4f}\".format(test_f1))\n",
    "    print(\"Test PrecisionScore:{:.4f}\".format(test_prec))\n",
    "    print(\"Test RecallScore:{:.4f}\".format(test_recall))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'colsample_bytree': np.float64(0.8950004992438994), 'gamma': np.float64(0.22610897044490358), 'learning_rate': np.float64(0.07738144688199458), 'max_depth': 14, 'min_child_weight': 3, 'n_estimators': 231, 'reg_alpha': np.float64(0.1763869865062233), 'reg_lambda': np.float64(0.5983677727394797), 'subsample': np.float64(0.7675701798018192)}\n",
      "Best accuracy:  0.9450070031900463\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "params= {\n",
    "    'n_estimators': randint(50, 400),\n",
    "    'max_depth': randint(3, 25),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0.1, 1)\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=100,\n",
    "                                   scoring='accuracy', n_jobs=-1, cv=5, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best accuracy: \", random_search.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
